# Prompts to regenerate the codes for "deep dive into the process of debugging llms with tools calls"

1. I am building a robust backend server (with NodeJS) and I want to practice looking under the hood of LLMs and how they interact with tools. My goal is to demistify the debugging process with some simple code and something that clearly shows how an LLM function calling can go wrong. Generate a simple code example and put bugs and errors in the main code and also in the functions as well and see how the LLM deals with it. I want to view the process and actually get the debugging results. Consider the function calling with the OpenAI API. Please provide the project setup instructions and how to develop the code from ground up in NodeJS.

This prompt will generate a codebase example potentially with separate files.

2. 